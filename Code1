import torch
import skfuzzy as fuzz
from networkx import Graph
import scipy.cluster.hierarchy as sch
import numpy as np

class FractalPerceptron:
    def __init__(self, fuzzy_network, depth):
        self.fuzzy_network = fuzzy_network
        self.depth = depth
        self.children = []
        self.optimizer = torch.optim.Adam(self.parameters(), lr=0.01)

    def forward(self, x):
        if self.depth == 1:
            return self.fuzzy_network(x)
        else:
            out = 0
            for child in self.children:
                out += child(x)
            return out

    def backward(self, grad_output):
        if self.depth == 1:
            self.fuzzy_network.backward(grad_output)
        else:
            grad_input = 0
            for child in self.children:
                child.backward(grad_output)
                grad_input += child.grad_input
            self.grad_input = grad_input

    def add_child(self, child):
        self.children.append(child)

    def parameters(self):
        if self.depth == 1:
            return self.fuzzy_network.parameters()
        else:
            return [param for child in self.children for param in child.parameters()]

class FuzzyNetwork:
    def __init__(self, input_size, output_size, num_rules):
        self.input_size = input_size
        self.output_size = output_size
        self.num_rules = num_rules
        self.input_mfs = []
        self.output_mfs = []
        self.rules = []
        self.optimizer = torch.optim.Adam(self.parameters(), lr=0.01)

        # Initialize input and output membership functions
        for i in range(input_size):
            self.input_mfs.append(fuzz.gaussmf(np.linspace(0, 1, num_rules), i/float(input_size), 0.1))
        for i in range(output_size):
            self.output_mfs.append(fuzz.gaussmf(np.linspace(0, 1, num_rules), i/float(output_size), 0.1))

        # Initialize rules
        for i in range(num_rules):
            for j in range(num_rules):
                rule = torch.tensor(np.fmin(self.input_mfs[i], self.input_mfs[j]), dtype=torch.float32)
                self.rules.append(rule)

    def forward(self, x):
        x = torch.tensor(x, dtype=torch.float32)
        inputs = []
        for i in range(self.input_size):
            inputs.append(self.input_mfs[i][x[i]])
        inputs = torch.tensor(inputs, dtype=torch.float32)
        outputs = torch.matmul(inputs, torch.stack(self.rules)).reshape(self.output_size, self.num_rules)
        outputs = torch.stack([torch.fmax(outputs[i], self.output_mfs[i]) for i in range(self.output_size)])
        outputs = torch.mean(outputs, dim=1)
        return outputs

    def backward(self, grad_output):
      grad_output = torch.tensor(grad_output, dtype=torch.float32)
      grad_input = torch.matmul(torch.stack(self.rules), grad_output.reshape(self.num_rules, 1)).reshape(self.num_rules*self.input_size)
      for i in range(self.input_size):
          grad_mf = torch.tensor(np.fmax(self.input_mfs[i], 1-self.input_mfs[i]), dtype=torch.float32)
          grad_mf[self.input_mfs[i] > 0.5] = 1 - grad_mf[self.input_mfs[i] > 0.5]
          grad_mf = grad_mf / grad_mf.sum()
          self.input_mfs[i] -= self.optimizer.param_groups[0]['lr'] * grad_input[i*self.num_rules:(i+1)*self.num_rules]
          grad_mf = grad_mf.unsqueeze(1)
          grad_rules = grad_output * grad_mf
          self.rules -= self.optimizer.param_groups[0]['lr'] * grad_rules.T                                                              
class FractalAutoML:
    def __init__(self, input_size, output_size, num_rules, fractal_depth):
          super(FractalAutoML, self).__init__()
          self.input_size = input_size
          self.output_size = output_size
          self.num_rules = num_rules
          self.fractal_depth = fractal_depth
          self.fuzzy_network = FuzzyNetwork(input_size, output_size, num_rules)
          self.fractal_perceptrons = []
          for depth in range(1, fractal_depth+1):
              self.fractal_perceptrons.append(FractalPerceptron(self.fuzzy_network, depth))

    def forward(self, x):
          out = 0
          for fractal_perceptron in self.fractal_perceptrons:
              out += fractal_perceptron(x)
          return out

    def train(self, train_data, epochs=10):
        for epoch in range(epochs):
            # Forward pass
            outputs = self(train_data)
            # Compute loss
            loss = torch.mean((outputs - train_labels)**2)
            # Backpropagate
            loss.backward()
            # Update parameters
            self.optimizer.step()
            # Print loss
            print(loss.item())

    def evaluate(self, test_data):
        outputs = self(test_data)
        loss = torch.mean((outputs - test_labels)**2)
        return loss

    def compress(self):
        # Get the teacher model
        teacher = FractalAutoML(self.input_size, self.output_size, self.num_rules, self.fractal_depth - 1)
        # Train the teacher model
        teacher.train(train_data, epochs=10)
        # Distil the knowledge from the teacher model to the student model
        self.distill(teacher)
        return self

    def distill(self, teacher):
        # Get the teacher's output
        teacher_outputs = teacher(train_data)
        # Get the student's output
        student_outputs = self(train_data)
        # Compute the distillation loss
        distillation_loss = torch.mean((teacher_outputs - student_outputs)**2)
        # Backpropagate the distillation loss
        distillation_loss.backward()
        # Update the student's parameters
        self.optimizer.step()

class Metagraph:
    def __init__(self):
        self.graph = Graph()

    def add_node(self, node):
        self.graph.add_node(node)

    def add_edge(self, node1, node2):
        self.graph.add_edge(node1, node2)

    def get_nodes(self):
        return self.graph.nodes()

    def get_edges(self):
        return self.graph.edges()

    def get_node_neighbors(self, node):
        return self.graph.neighbors(node)                                                                                                                                                 
class InternetOfModels:
    def __init__(self):
        self.models = []
        self.metagraph = Metagraph()

    def connect_to_model(self, model_url):
        model = FractalAutoML(model_url)
        self.models.append(model)
        self.metagraph.add_node(model)

    def train(self, data):
        for model in self.models:
            model.train(data)
        self.metagraph.update_edges()

    def predict(self, input_data):
        predictions = []
        for model in self.models:
            predictions.append(model.predict(input_data))
        return predictions
